{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeScraper:\n",
    "    def __init__(self, max_retries=3, timeout=10):\n",
    "        self.max_retries = max_retries\n",
    "        self.timeout = timeout\n",
    "        self.data_recetas = []\n",
    "        self.corpus = []  # Corpus para títulos y descripciones\n",
    "        self.setup_driver()\n",
    "        self.recipe_count = 0\n",
    "\n",
    "    def setup_driver(self):\n",
    "        options = webdriver.FirefoxOptions()\n",
    "        options.add_argument('--disable-gpu')\n",
    "        options.add_argument('--no-sandbox')\n",
    "        options.add_argument('--disable-dev-shm-usage')\n",
    "        \n",
    "        self.driver = webdriver.Firefox(\n",
    "            service=Service(GeckoDriverManager().install()),\n",
    "            options=options\n",
    "        )\n",
    "        self.wait = WebDriverWait(self.driver, self.timeout)\n",
    "    \n",
    "    def random_delay(self, min_delay=1, max_delay=3):\n",
    "        time.sleep(random.uniform(min_delay, max_delay))\n",
    "\n",
    "    def find_element_safely(self, by, value, parent=None):\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                if parent:\n",
    "                    return parent.find_element(by, value)\n",
    "                return self.wait.until(EC.presence_of_element_located((by, value)))\n",
    "            except (TimeoutException, NoSuchElementException, StaleElementReferenceException) as e:\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    raise e\n",
    "                self.random_delay()\n",
    "\n",
    "    def find_elements_safely(self, by, value, parent=None):\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                if parent:\n",
    "                    return parent.find_elements(by, value)\n",
    "                return self.wait.until(EC.presence_of_all_elements_located((by, value)))\n",
    "            except (TimeoutException, NoSuchElementException, StaleElementReferenceException) as e:\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    raise e\n",
    "                self.random_delay()\n",
    "\n",
    "    def scrape_categories(self):\n",
    "        self.driver.get(\"https://www.allrecipes.com/ingredients-a-z-6740416\")\n",
    "        \n",
    "        for i in range(1, 17):\n",
    "            try:\n",
    "                div_element = self.find_element_safely(\n",
    "                    By.XPATH, f'/html/body/main/div[2]/div[{i}]'\n",
    "                )\n",
    "                categoria = self.find_element_safely(\n",
    "                    By.TAG_NAME, 'h3', div_element\n",
    "                ).text.strip()\n",
    "                \n",
    "                ul_element = self.find_element_safely(\n",
    "                    By.XPATH, f'/html/body/main/div[2]/div[{i}]/ul'\n",
    "                )\n",
    "                \n",
    "                li_elements = self.find_elements_safely(By.TAG_NAME, 'li', ul_element)\n",
    "                \n",
    "                for li in li_elements:\n",
    "                    try:\n",
    "                        a_element = self.find_element_safely(By.TAG_NAME, 'a', li)\n",
    "                        ingrediente = a_element.text.strip()\n",
    "                        link_ingrediente = a_element.get_attribute('href')\n",
    "                        \n",
    "                        # Solo guardamos la información básica del ingrediente\n",
    "                        self.data_recetas.append({\n",
    "                            'categoria': categoria,\n",
    "                            'ingrediente': ingrediente,\n",
    "                            'link_ingrediente': link_ingrediente\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        text = text.lower()  # Convertir a minúsculas\n",
    "        text = re.sub(r'[^a-záéíóúüñ\\s]', '', text)  # Eliminar caracteres especiales\n",
    "        tokens = word_tokenize(text, language='spanish')  # Tokenización\n",
    "        stop_words = set(stopwords.words('spanish'))  # Palabras vacías en español\n",
    "        filtered_tokens = [word for word in tokens if word not in stop_words]  # Eliminar stopwords\n",
    "        return ' '.join(filtered_tokens)\n",
    "\n",
    "    def extract_recipe_info(self, link_element, base_info):\n",
    "        try:\n",
    "            link_receta = link_element.get_attribute('href')\n",
    "            titulo_receta = self.find_element_safely(\n",
    "                By.XPATH, './/div[2]/span/span', link_element\n",
    "            ).text.strip()\n",
    "            \n",
    "            # Preprocesar el título\n",
    "            preprocessed_title = self.preprocess_text(titulo_receta)\n",
    "            \n",
    "            # Ingresar al link de la receta para extraer la descripción\n",
    "            self.driver.get(link_receta)\n",
    "            self.random_delay()\n",
    "            \n",
    "            # Buscar el párrafo de la descripción dentro del xpath especificado\n",
    "            description_element = self.find_element_safely(By.XPATH, \"//*[@id='article-header--recipe_1-0']//p\")\n",
    "            descripcion_receta = description_element.text.strip() if description_element else \"Descripción no disponible\"\n",
    "            \n",
    "            # Preprocesar la descripción\n",
    "            preprocessed_description = self.preprocess_text(descripcion_receta)\n",
    "            \n",
    "            # Agregar al corpus\n",
    "            self.corpus.append(preprocessed_title + ' ' + preprocessed_description)\n",
    "            \n",
    "            return {\n",
    "                'categoria': base_info['categoria'],\n",
    "                'ingrediente': base_info['ingrediente'],\n",
    "                'link_ingrediente': base_info['link_ingrediente'],\n",
    "                'link_receta': link_receta,\n",
    "                'titulo_receta': titulo_receta,\n",
    "                'descripcion_receta': descripcion_receta\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return None\n",
    "\n",
    "    def scrape_recipes(self, max_recipes=500):\n",
    "        recipes_data = []\n",
    "        \n",
    "        for ingrediente_info in self.data_recetas:\n",
    "            if self.recipe_count >= max_recipes:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                self.driver.get(ingrediente_info['link_ingrediente'])\n",
    "                self.random_delay()\n",
    "                \n",
    "                for xpath in [\n",
    "                    '//*[@id=\"mntl-document-spotlight_1-0\"]',\n",
    "                    '//*[@id=\"mntl-taxonomysc-article-list-group_1-0\"]'\n",
    "                ]:\n",
    "                    if self.recipe_count >= max_recipes:\n",
    "                        break\n",
    "                        \n",
    "                    try:\n",
    "                        container = self.find_element_safely(By.XPATH, xpath)\n",
    "                        recipe_links = self.find_elements_safely(By.TAG_NAME, 'a', container)\n",
    "                        \n",
    "                        for link in recipe_links:\n",
    "                            if self.recipe_count >= max_recipes:\n",
    "                                break\n",
    "                                \n",
    "                            recipe_info = self.extract_recipe_info(link, ingrediente_info)\n",
    "                            if recipe_info:\n",
    "                                recipes_data.append(recipe_info)\n",
    "                                self.recipe_count += 1\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        self.data_recetas = recipes_data\n",
    "\n",
    "    def save_data(self, filename='ingredientes_recetas_completo.csv', corpus_filename='corpus.txt'):\n",
    "        try:\n",
    "            df = pd.DataFrame(self.data_recetas)\n",
    "            df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"Se extrajeron {self.recipe_count} recetas en total\")\n",
    "            \n",
    "            with open(corpus_filename, 'w', encoding='utf-8') as f:\n",
    "                for item in self.corpus:\n",
    "                    f.write(\"%s\\n\" % item)\n",
    "            print(f\"Corpus guardado en {corpus_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error guardando datos: {str(e)}\")\n",
    "\n",
    "    def cleanup(self):\n",
    "        try:\n",
    "            self.driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error cerrando el navegador: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def find_element_safely(self, by, value, parent=None):\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                if parent:\n",
    "                    return parent.find_element(by, value)\n",
    "                return self.wait.until(EC.presence_of_element_located((by, value)))\n",
    "            except (TimeoutException, NoSuchElementException, StaleElementReferenceException) as e:\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    raise e\n",
    "                self.random_delay()\n",
    "\n",
    "    def find_elements_safely(self, by, value, parent=None):\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                if parent:\n",
    "                    return parent.find_elements(by, value)\n",
    "                return self.wait.until(EC.presence_of_all_elements_located((by, value)))\n",
    "            except (TimeoutException, NoSuchElementException, StaleElementReferenceException) as e:\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    raise e\n",
    "                self.random_delay()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def scrape_categories(self):\n",
    "        \"\"\"Extrae las categorías e ingredientes iniciales\"\"\"\n",
    "        self.driver.get(\"https://www.allrecipes.com/ingredients-a-z-6740416\")\n",
    "        \n",
    "        for i in range(1, 17):\n",
    "            try:\n",
    "                div_element = self.find_element_safely(\n",
    "                    By.XPATH, f'/html/body/main/div[2]/div[{i}]'\n",
    "                )\n",
    "                categoria = self.find_element_safely(\n",
    "                    By.TAG_NAME, 'h3', div_element\n",
    "                ).text.strip()\n",
    "                \n",
    "                ul_element = self.find_element_safely(\n",
    "                    By.XPATH, f'/html/body/main/div[2]/div[{i}]/ul'\n",
    "                )\n",
    "                \n",
    "                li_elements = self.find_elements_safely(By.TAG_NAME, 'li', ul_element)\n",
    "                \n",
    "                for li in li_elements:\n",
    "                    try:\n",
    "                        a_element = self.find_element_safely(By.TAG_NAME, 'a', li)\n",
    "                        ingrediente = a_element.text.strip()\n",
    "                        link_ingrediente = a_element.get_attribute('href')\n",
    "                        \n",
    "                        # Solo guardamos la información básica del ingrediente\n",
    "                        self.data_recetas.append({\n",
    "                            'categoria': categoria,\n",
    "                            'ingrediente': ingrediente,\n",
    "                            'link_ingrediente': link_ingrediente\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "            except Exception as e:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Preprocesa el texto: convierte a minúsculas, elimina caracteres especiales y stopwords\"\"\"\n",
    "        text = text.lower()  # Convertir a minúsculas\n",
    "        text = re.sub(r'[^a-záéíóúüñ\\s]', '', text)  # Eliminar caracteres especiales\n",
    "        tokens = word_tokenize(text, language='spanish')  # Tokenización\n",
    "        stop_words = set(stopwords.words('spanish'))  # Palabras vacías en español\n",
    "        filtered_tokens = [word for word in tokens if word not in stop_words]  # Eliminar stopwords\n",
    "        return ' '.join(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def extract_recipe_info(self, link_element, base_info):\n",
    "        \"\"\"Extrae información de una receta individual\"\"\"\n",
    "        try:\n",
    "            link_receta = link_element.get_attribute('href')\n",
    "            titulo_receta = self.find_element_safely(\n",
    "                By.XPATH, './/div[2]/span/span', link_element\n",
    "            ).text.strip()\n",
    "            \n",
    "            # Preprocesar el título\n",
    "            preprocessed_title = self.preprocess_text(titulo_receta)\n",
    "            \n",
    "            # Ingresar al link de la receta para extraer la descripción\n",
    "            self.driver.get(link_receta)\n",
    "            self.random_delay()\n",
    "            \n",
    "            # Buscar el párrafo de la descripción dentro del xpath especificado\n",
    "            description_element = self.find_element_safely(By.XPATH, \"//*[@id='article-header--recipe_1-0']//p\")\n",
    "            descripcion_receta = description_element.text.strip() if description_element else \"Descripción no disponible\"\n",
    "            \n",
    "            # Preprocesar la descripción\n",
    "            preprocessed_description = self.preprocess_text(descripcion_receta)\n",
    "            \n",
    "            # Agregar al corpus\n",
    "            self.corpus.append(preprocessed_title + ' ' + preprocessed_description)\n",
    "            \n",
    "            return {\n",
    "                'categoria': base_info['categoria'],\n",
    "                'ingrediente': base_info['ingrediente'],\n",
    "                'link_ingrediente': base_info['link_ingrediente'],\n",
    "                'link_receta': link_receta,\n",
    "                'titulo_receta': titulo_receta,\n",
    "                'descripcion_receta': descripcion_receta\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def scrape_recipes(self, max_recipes=500):\n",
    "        \"\"\"Extrae las recetas para cada ingrediente hasta alcanzar el límite\"\"\"\n",
    "        recipes_data = []\n",
    "        \n",
    "        for ingrediente_info in self.data_recetas:\n",
    "            if self.recipe_count >= max_recipes:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                self.driver.get(ingrediente_info['link_ingrediente'])\n",
    "                self.random_delay()\n",
    "                \n",
    "                # Intentar ambas secciones de recetas\n",
    "                for xpath in [\n",
    "                    '//*[@id=\"mntl-document-spotlight_1-0\"]',\n",
    "                    '//*[@id=\"mntl-taxonomysc-article-list-group_1-0\"]'\n",
    "                ]:\n",
    "                    if self.recipe_count >= max_recipes:\n",
    "                        break\n",
    "                        \n",
    "                    try:\n",
    "                        container = self.find_element_safely(By.XPATH, xpath)\n",
    "                        recipe_links = self.find_elements_safely(By.TAG_NAME, 'a', container)\n",
    "                        \n",
    "                        for link in recipe_links:\n",
    "                            if self.recipe_count >= max_recipes:\n",
    "                                break\n",
    "                                \n",
    "                            recipe_info = self.extract_recipe_info(link, ingrediente_info)\n",
    "                            if recipe_info:\n",
    "                                recipes_data.append(recipe_info)\n",
    "                                self.recipe_count += 1\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        self.data_recetas = recipes_data  # Reemplazamos con los datos completos de recetas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def save_data(self, filename='ingredientes_recetas_completo.csv', corpus_filename='corpus.txt'):\n",
    "        try:\n",
    "            # Guardar datos en CSV\n",
    "            df = pd.DataFrame(self.data_recetas)\n",
    "            df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"Se extrajeron {self.recipe_count} recetas en total\")\n",
    "            \n",
    "            # Guardar el corpus en un archivo de texto\n",
    "            with open(corpus_filename, 'w', encoding='utf-8') as f:\n",
    "                for item in self.corpus:\n",
    "                    f.write(\"%s\\n\" % item)\n",
    "            print(f\"Corpus guardado en {corpus_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error guardando datos: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def cleanup(self):\n",
    "        try:\n",
    "            self.driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error cerrando el navegador: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se extrajeron 3 recetas en total\n",
      "Corpus guardado en corpus.txt\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    scraper = None\n",
    "    try:\n",
    "        scraper = RecipeScraper()\n",
    "        scraper.scrape_categories()\n",
    "        scraper.scrape_recipes(max_recipes=3)  # Límite de 500 recetas\n",
    "        scraper.save_data()\n",
    "    except Exception as e:\n",
    "        print(f\"Error en la ejecución principal: {str(e)}\")\n",
    "    finally:\n",
    "        if scraper:\n",
    "            scraper.cleanup()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
